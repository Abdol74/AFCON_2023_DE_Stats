{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00e95fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import * \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c30069",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = \"/home/abdol/AFCON_2023_DE_Stats/code/mage-spark/keys/my-creds.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfc50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"/home/abdol/AFCON_2023_DE_Stats/lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9349c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/04 00:14:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9dca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_conf = sc._jsc.hadoopConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d32e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517b117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fcc604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "matches_df = spark.read.parquet(\"gs://cloud_bucket_dbt/acfon_matches.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b531bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571b0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- match_id: long (nullable = true)\n",
      " |-- match_date: string (nullable = true)\n",
      " |-- kick_off: string (nullable = true)\n",
      " |-- competition: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- home_team: string (nullable = true)\n",
      " |-- away_team: string (nullable = true)\n",
      " |-- home_score: long (nullable = true)\n",
      " |-- away_score: long (nullable = true)\n",
      " |-- match_week: long (nullable = true)\n",
      " |-- competition_stage: string (nullable = true)\n",
      " |-- stadium: string (nullable = true)\n",
      " |-- referee: string (nullable = true)\n",
      " |-- home_managers: string (nullable = true)\n",
      " |-- away_managers: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "564db1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdol/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "matches_df.registerTempTable('Matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4540ddab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-------------------------------+------+-------------+-------------+----------+----------+----------+-----------------+-----------------------------------------+---------------------+-----------------------------+-----------------+-------------+\n",
      "|match_id|match_date|kick_off    |competition                    |season|home_team    |away_team    |home_score|away_score|match_week|competition_stage|stadium                                  |referee              |home_managers                |away_managers    |source       |\n",
      "+--------+----------+------------+-------------------------------+------+-------------+-------------+----------+----------+----------+-----------------+-----------------------------------------+---------------------+-----------------------------+-----------------+-------------+\n",
      "|3923881 |2024-02-11|22:00:00.000|Africa - African Cup of Nations|2023  |Nigeria      |Côte d'Ivoire|1         |2         |8         |Final            |Stade Olympique Alassane Ouattara        |Dahane Beida         |José Vítor dos Santos Peseiro|Emerse Faé       |acfon_matches|\n",
      "|3923880 |2024-02-10|22:00:00.000|Africa - African Cup of Nations|2023  |South Africa |Congo DR     |0         |0         |7         |3rd Place Final  |Stade Félix Houphouët-Boigny             |Bamlak Tessema Weyesa|Hugo Henri Broos             |Sébastien Desabre|acfon_matches|\n",
      "|3922838 |2024-02-07|22:00:00.000|Africa - African Cup of Nations|2023  |Côte d'Ivoire|Congo DR     |1         |0         |6         |Semi-finals      |Stade Olympique Alassane Ouattara        |Ibrahim Mutaz        |Emerse Faé                   |Sébastien Desabre|acfon_matches|\n",
      "|3922837 |2024-02-07|19:00:00.000|Africa - African Cup of Nations|2023  |Nigeria      |South Africa |1         |1         |6         |Semi-finals      |Stade de Bouaké                          |Amin Mohamed Omar    |José Vítor dos Santos Peseiro|Hugo Henri Broos |acfon_matches|\n",
      "|3922242 |2024-01-29|22:00:00.000|Africa - African Cup of Nations|2023  |Senegal      |Côte d'Ivoire|1         |1         |4         |Round of 16      |Stade Charles Konan Banny de Yamoussoukro|Pierre Ghislain Atcho|Aliou Cissé                  |Emerse Faé       |acfon_matches|\n",
      "+--------+----------+------------+-------------------------------+------+-------------+-------------+----------+----------+----------+-----------------+-----------------------------------------+---------------------+-----------------------------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "matches_df.show(n=5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de47c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "events_df = spark.read.parquet(\"gs://cloud_bucket_dbt/match_events.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18751e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288671"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb9a484",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- foul_committed_penalty: boolean (nullable = true)\n",
      " |-- foul_won_penalty: boolean (nullable = true)\n",
      " |-- player: string (nullable = true)\n",
      " |-- player_id: double (nullable = true)\n",
      " |-- match_id: double (nullable = true)\n",
      " |-- team: string (nullable = true)\n",
      " |-- team_id: double (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- location: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- play_pattern: string (nullable = true)\n",
      " |-- foul_committed_card: string (nullable = true)\n",
      " |-- foul_committed_offensive: boolean (nullable = true)\n",
      " |-- foul_committed_type: string (nullable = true)\n",
      " |-- foul_won_defensive: boolean (nullable = true)\n",
      " |-- minute: double (nullable = true)\n",
      " |-- pass_goal_assist: boolean (nullable = true)\n",
      " |-- pass_shot_assist: boolean (nullable = true)\n",
      " |-- pass_outcome: string (nullable = true)\n",
      " |-- pass_cross: boolean (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- possession: double (nullable = true)\n",
      " |-- possession_team: string (nullable = true)\n",
      " |-- interception_outcome: string (nullable = true)\n",
      " |-- shot_outcome: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc88b01",
   "metadata": {},
   "source": [
    "#####  define dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a21466",
   "metadata": {},
   "source": [
    "##### team dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "181eef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = spark.sql(\"\"\"\n",
    "            SELECT DISTINCT \n",
    "            home_team\n",
    "            FROM Matches\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcb67be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Teams.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e11defe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Team_ID|Team_Name         |\n",
      "+-------+------------------+\n",
      "|0      |Côte d'Ivoire     |\n",
      "|1      |Senegal           |\n",
      "|2      |Equatorial Guinea |\n",
      "|3      |Congo DR          |\n",
      "|4      |Algeria           |\n",
      "|5      |Angola            |\n",
      "|6      |Ghana             |\n",
      "|7      |Nigeria           |\n",
      "|8      |Mauritania        |\n",
      "|9      |Morocco           |\n",
      "|10     |Tunisia           |\n",
      "|11     |Namibia           |\n",
      "|12     |Zambia            |\n",
      "|13     |Guinea            |\n",
      "|14     |Cape Verde Islands|\n",
      "|15     |Mozambique        |\n",
      "|16     |Gambia            |\n",
      "|17     |Tanzania          |\n",
      "|18     |Cameroon          |\n",
      "|19     |Guinea-Bissau     |\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Teams.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d9d6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = Teams.withColumn('Team_ID',monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "973f73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = Teams.withColumnRenamed('home_team','Team_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2db0e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = Teams.select('Team_ID','Team_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96d1f573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Team_ID: long (nullable = false)\n",
      " |-- Team_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Teams.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d765f",
   "metadata": {},
   "source": [
    "##### Staduims dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e7ab6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Staduim = spark.sql(\"\"\"\n",
    "            SELECT DISTINCT stadium\n",
    "            FROM Matches\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2cdc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Staduim = Staduim.withColumn('Staduim_ID',monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d13c2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Staduim = Staduim.select('Staduim_ID', 'stadium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ece71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------+\n",
      "|Staduim_ID|stadium                                  |\n",
      "+----------+-----------------------------------------+\n",
      "|0         |Stade Laurent Pokou                      |\n",
      "|1         |Stade Amadou Gon Coulibaly               |\n",
      "|2         |Stade de Bouaké                          |\n",
      "|3         |Stade Charles Konan Banny de Yamoussoukro|\n",
      "|4         |Stade Félix Houphouët-Boigny             |\n",
      "|5         |Stade Olympique Alassane Ouattara        |\n",
      "+----------+-----------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Staduim.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7480e",
   "metadata": {},
   "source": [
    "##### Referee Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db1999e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Referee = spark.sql(\"\"\"\n",
    "                    SELECT DISTINCT referee\n",
    "                    FROM Matches\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63d1e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Referee = Referee.withColumn('referee_id', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4275d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Referee = Referee.select('referee_id', 'referee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5af54c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------+\n",
      "|referee_id|referee                    |\n",
      "+----------+---------------------------+\n",
      "|0         |Ibrahim Mutaz              |\n",
      "|1         |Mustapha Ghorbal           |\n",
      "|2         |Abdel Aziz Mohamed Bouh    |\n",
      "|3         |Omar Abdulkadir Artan      |\n",
      "|4         |Bouchra Karboubi           |\n",
      "|5         |Mohamed Maarouf Eid Mansour|\n",
      "|6         |Jalal Jayed                |\n",
      "|7         |Redouane Jiyed             |\n",
      "|8         |Mohamed Adel Elsaid        |\n",
      "|9         |Abdulkadir Artan           |\n",
      "|10        |Mahmood Ali Mahmood Ismail |\n",
      "|11        |Peter Waweru Kamaku        |\n",
      "|12        |Alhadi Allaou Mahamat      |\n",
      "|13        |Pierre Ghislain Atcho      |\n",
      "|14        |Daniel Nii Ayi Laryea      |\n",
      "|15        |Mohamed Adel Hussein       |\n",
      "|16        |Dahane Beida               |\n",
      "|17        |Abongile Tom               |\n",
      "|18        |Issa Sy                    |\n",
      "|19        |Bamlak Tessema Weyesa      |\n",
      "+----------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Referee.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd11614",
   "metadata": {},
   "source": [
    "##### Manager Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96d41c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manager = spark.sql(\"\"\"\n",
    "                    SELECT DISTINCT home_managers \n",
    "                    FROM Matches\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad0c379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manager = Manager.withColumn(\"manager_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82454ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manager = Manager.withColumnRenamed('home_managers', 'manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b393e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manager.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48d941f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 63:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+----------+\n",
      "|manager                        |manager_id|\n",
      "+-------------------------------+----------+\n",
      "|Emerse Faé                     |0         |\n",
      "|Rui Carlos Pinho da Vitória    |1         |\n",
      "|Avraham Grant                  |2         |\n",
      "|Éric Chelle                    |3         |\n",
      "|Djamel Belmadi                 |4         |\n",
      "|Pedro Valdemar Soares Gonçalves|5         |\n",
      "|José Vítor dos Santos Peseiro  |6         |\n",
      "|Collin Benjamin                |7         |\n",
      "|Chris Hughton                  |8         |\n",
      "|Rigobert Song Bahanag          |9         |\n",
      "|Baciro Candé                   |10        |\n",
      "|Jalel Kadri                    |11        |\n",
      "|Amir Abdou                     |12        |\n",
      "|Aliou Cissé                    |13        |\n",
      "|Francisco Queriol Conde Júnior |14        |\n",
      "|Tom Saintfiet                  |15        |\n",
      "|Hemed Suleiman Ali             |16        |\n",
      "|Hugo Henri Broos               |17        |\n",
      "|Juan Micha Obiang Bicogo       |18        |\n",
      "|Pedro Leitão Brito             |19        |\n",
      "+-------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Manager.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd46181",
   "metadata": {},
   "source": [
    "##### Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1c0043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min_date_from_src():\n",
    "    max_min_date_list = spark.sql(\"\"\"\n",
    "                        SELECT \n",
    "                                MIN(match_date) AS min_match_date,\n",
    "                                MAX(match_date) AS max_match_date\n",
    "                        FROM \n",
    "                                Matches\n",
    "            \"\"\").collect()\n",
    "    \n",
    "    \n",
    "    start_date = to_date(lit(max_min_date_list[0]['min_match_date']), \"%Y-%m-%d\")\n",
    "    max_date = to_date(lit(max_min_date_list[0]['max_match_date']), \"%Y-%m-%d\")\n",
    "    \n",
    "\n",
    "    \n",
    "    dates = spark.range(start_date.subtract(days=1), max_date.add(days=1), 1).select(\"id\").alias(\"date_id\")\n",
    "    \n",
    "    dates = dates.withColumn(\"date\", date_add(start_date, col(\"date_id\") - 1))\n",
    "\n",
    "    \n",
    "    dates = dates.withColumn(\"year\", year(col(\"date\")))\n",
    "    dates = dates.withColumn(\"month\", month(col(\"date\")))\n",
    "    dates = dates.withColumn(\"day_of_week\", dayofweek(col(\"date\")))\n",
    "    dates = dates.withColumn(\"id\", monotonically_increasing_id())                        \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc4b7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_max_min_date_from_src()\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[96], line 16\u001b[0m, in \u001b[0;36mget_max_min_date_from_src\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m start_date \u001b[38;5;241m=\u001b[39m to_date(lit(max_min_date_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_match_date\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m max_date \u001b[38;5;241m=\u001b[39m to_date(lit(max_min_date_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_match_date\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m dates \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mrange(start_date\u001b[38;5;241m.\u001b[39msubtract(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), max_date\u001b[38;5;241m.\u001b[39madd(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m dates \u001b[38;5;241m=\u001b[39m dates\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, date_add(start_date, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     21\u001b[0m dates \u001b[38;5;241m=\u001b[39m dates\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, year(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "get_max_min_date_from_src().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5b5df638",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
